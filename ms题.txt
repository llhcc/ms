为什么要学习java:
具有简单，面向对象稳定，与平台无关，解释型，多线程，动态等特点。
2.解释型 
我们知道C，C++等语言，都是只能对特定的CPU芯片进行编译，生成机器代码，该代码的运行就和特定的CPU有关。Java不像C++，它不针对特定的CPU芯片进行编译，而是把程序编译为称做字节码的一个“中间代码”。即翻译一句，执行一句，不产生整个的机器代码程序。
3.简单 Java 语言简单是指这门语言既易学有好用。学习过 C++语言，会感觉 Java很眼熟，但从语言的简单性方面看，Java要比 
C++简单，C++中许多容易混淆的概念，或被Java弃之不用了，或以一种更清楚更容易理解的方式实现。
4.与平台无关 与平台无关是 Java 语言最大的优势。其它语言编写的程序面临的一个主要问题是 
操作系统的变化，处理器升级以及核心系统资源的变化，都可能导致程序出现错误或无法运行。Java的虚拟机成功地解决了这个问题，Java编写的程序可以在任何安装了 
Java虚拟机 JVM 的计算机上正确的运行。
5.面向对象 基于对象的编程更符合人的思维模式，使人们更容易编写程序。Java 
语言与其它面向对象语言一样，引入了类的概念，类是用来创建对象的模板，它包含被创建的对象的状态描述和方法的定义。
6.安全 
当你准备从网络上下载一个程序时，你最大的担心是程序中含有恶意的代码，比如试图读取或删除本地机上的一些重要文件，甚至该程序是一个病毒程序等。当你使用支持Java的浏览器时，你可以放心地运行Java的小应用程序 
Java Applet ，不必担心病毒的感染和恶意的企图，Java小应用程序将限制在 Java运行环境中，不允许它访问计算机的其它部分。
7.多线程 Java 
的特点之一就是内置对多线程的支持。多线程允许同时完成多个任务。实际上多线程使人产生多个任务在同时执行的错觉，因为，目前的计算机的处理器在同一时刻只能执行一个线程，但处理器可以在不同的线程之间快速地切换，由于处理器速度非常快，远远超过了人接收信息的速度，所以给人的感觉好象多个任务在同时执行。
 8.动态 Java 程序的基本组成单元就是类，有些类是自己编写的，有一些是从类库中引入的，而类又是运行时动态装载的，这就使得 Java 
可以在分布环境中动态地维护程序及类库。
-------------------------------------------------------------
zookeeper：集群管理，配置管理，统一命名服务，负载
算法：leaderElection，fastleaderElection，autofastleaderElection
following，leader，observing，looking
投票选举算法
根据每份数据id最大，id越大数据越新，投票，然后广播出去，

Zookeeper是Hadoop下的一个子项目，它是一个针对大型分布式系统的可靠的协调系统，提供的功能包括命名服务、配置维护、分布式同步、集群服务等。

　　Zookeeper是可以集群复制的，集群间通过Zab(Zookeeper Atomic Broadcast)协议来保持数据的一致性。

　　该协议包括2个阶段：leader election阶段和Actomic broadcast阶段。集群中将选举出一个leader，其他的机器则称为follower，所有的写操作都被传送给leader，
并通过broadcast将所有的更新告诉follower。当leader崩溃或者leader失去大多数的follower时，需要重新选举出一个新的leader，让所有的服务器都恢复到一个正确的状态。
当leader被选举出来，且大多数服务器完成了和leader的状态同步后，leader election的过程就结束了，将进入Atomic broadcast的过程。
Actomic broadcast同步leader和follower之间的信息，保证leader和follower具备相同的系统状态。

只有当配置信息更新时服务消费者才会去Zookeeper上获取最新的服务地址列表，其他时候使用本地缓存即可，这样服务消费者在服务信息没有变更时，几乎不依赖配置中心，能大大降低配置中心的压力。

paxos算法：最有效的消息传递的一致性算法。（举例：多个公司招标项目贿赂）

-----------------------------------------------------------
dubbo

-----------------------------------------------------------
生产者消费者：synchronized显示锁，Lock,ReentraLock,Condition显示锁，LinkedBlockingQueue

-----------------------------------------------------------
java内存模型：JMM
目标是定义程序中各个变量的访问规则。(包括实例字段、静态字段和构成数组的元素，不包括局部变量和方法参数)
所有的变量都存储在主内存中(虚拟机内存的一部分)。
每条线程都由自己的工作内存，线程的工作内存中保存了该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。
线程之间无法直接访问对方的工作内存中的变量，线程间变量的传递均需要通过主内存来完成。
内存间交互操作：

Lock(锁定)：作用于主内存中的变量，把一个变量标识为一条线程独占的状态。

Read(读取)：作用于主内存中的变量，把一个变量的值从主内存传输到线程的工作内存中。

Load(加载)：作用于工作内存中的变量，把read操作从主内存中得到的变量的值放入工作内存的变量副本中。

Use(使用)：作用于工作内存中的变量，把工作内存中一个变量的值传递给执行引擎。

Assign(赋值)：作用于工作内存中的变量，把一个从执行引擎接收到的值赋值给工作内存中的变量。

Store(存储)：作用于工作内存中的变量，把工作内存中的一个变量的值传送到主内存中。

Write(写入)：作用于主内存中的变量，把store操作从工作内存中得到的变量的值放入主内存的变量中。

Unlock(解锁)：作用于主内存中的变量，把一个处于锁定状态的变量释放出来，之后可被其它线程锁定。
规则：

不允许read和load、store和write操作之一单独出现。
不允许一个线程丢弃最近的assign操作，变量在工作内存中改变了之后必须把该变化同步回主内存中。
不允许一个线程没有发生过任何assign操作把数据从线程的工作内存同步回主内存中。
一个新的变量只能在主内存中诞生。
一个变量在同一时刻只允许一条线程对其进行lock操作，但可以被同一条线程重复执行多次。
如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行read、load操作。
如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作。
8.     对一个变量执行unlock操作前，必须先把该变量同步回主内存中。

---------------------------------------------------------------
HashMap是Hashtable的轻量级实现（非线程安全的实现），他们都完成了Map接口，
主要区别在于HashMap允许空（null）键值（key）,由于非线程安全，效率上可能高于Hashtable。
HashMap允许将null作为一个entry的key或者value，而Hashtable不允许。
HashMap把Hashtable的contains方法去掉了，改成containsvalue和containsKey。因为contains方法容易让人引起误解。 
Hashtable继承自Dictionary类，而HashMap是Java1.2引进的Map interface的一个实现。
最大的不同是，Hashtable的方法是Synchronize的，而HashMap不是，在多个线程访问Hashtable时，不需要自己为它的方法实现同步，而HashMap 就必须为之提供外同步(Collections.synchronizedMap)。 
Hashtable和HashMap采用的hash/rehash算法都大概一样，所以性能不会有很大的差异。

HashMap原理：
数组的特点是：寻址容易，插入和删除困难；
链表的特点是：寻址困难，插入和删除容易。

---------------------------------------------------------------
StringBuilder >  StringBuffer  >  String
---------------------------------------------------------------
抽象类与接口：
接口和抽象类的概念不一样。接口是对动作的抽象，抽象类是对根源的抽象。
抽象类表示的是，这个对象是什么。接口表示的是，这个对象能做什么。比如，男人，女人，这两个类（如果是类的话……），他们的抽象类是人。说明，他们都是人。
人可以吃东西，狗也可以吃东西，你可以把“吃东西”定义成一个接口，然后让这些类去实现它.
所以，在高级语言上，一个类只能继承一个类（抽象类）(正如人不可能同时是生物和非生物)，但是可以实现多个接口(吃饭接口、走路接口)。

1、抽象类和接口都不能直接实例化，如果要实例化，抽象类变量必须指向实现所有抽象方法的子类对象，接口变量必须指向实现所有接口方法的类对象。
2、抽象类要被子类继承，接口要被类实现。
3、接口只能做方法申明，抽象类中可以做方法申明，也可以做方法实现
4、接口里定义的变量只能是公共的静态的常量，抽象类中的变量是普通变量。
5、抽象类里的抽象方法必须全部被子类所实现，如果子类不能全部实现父类抽象方法，那么该子类只能是抽象类。同样，一个实现接口的时候，如不能全部实现接口方法，那么该类也只能为抽象类。
6、抽象方法只能申明，不能实现，接口是设计的结果 ，抽象类是重构的结果
7、抽象类里可以没有抽象方法
8、如果一个类里有抽象方法，那么这个类只能是抽象类
9、抽象方法要被实现，所以不能是静态的，也不能是私有的。
10、接口可继承接口，并可多继承接口，但类只能单根继承。
--------------------------------------------------------------
面向对象：
面向对象的三大特征： 
封装：找到变化并且把它封装起来，你就可以在不影响其它部分的情况下修改或扩展被封装的变化部分，这是所有设计模式的基础，就是封装变化，因此封装的作用，就解决了程序的可扩展性。 
继承：子类继承父类，可以继承父类的方法及属性，实现了多态以及代码的重用，因此也解决了系统的重用性和扩展性，但是继承破坏了封装，因为他是对子类开放的，
      修改父类会导致所有子类的改变，因此继承一定程度上又破坏了系统的可扩展性，所以继承需要慎用，只有明确的IS-A关系才能使用，同时继承在在程序开发过程中重构得到的，
      而不是程序设计之初就使用继承，很多面向对象开发者滥用继承，结果造成后期的代码解决不了需求的变化了。因此优先使用组合，而不是继承，
      是面向对象开发中一个重要的经验。 
多态：接口的多种不同的实现方式即为多态。接口是对行为的抽象，刚才在封装提到，找到变化部分并封装起来，但是封装起来后，怎么适应接下来的变化？
      这正是接口的作用，接口的主要目的是为不相关的类提供通用的处理服务,我们可以想象一下。比如鸟会飞，但是超人也会飞，通过飞这个接口，我们可以让鸟和超人，
      都实现这个接口，这就实现了系统的可维护性，可扩展性。 
因此面向对象能实现人们追求的系统可维护性，可扩展性，可重用性。面向对象是一种编程思想，起初，“面向对象”是专指在程序设计中采用封装、继承、多态等设计方法，
但面向对象的思想已经涉及到软件开发的各个方面，比如现在细分为了面向对象的分析(OOA)，面向对象的设计(OOD)，面向对象的编程实现(OOP) 
---------------------------------------------------------------
Tomcat组成：
1. Server：代表整个 servlet 容器。
2. Service：它由一个或者多个Connector组成，以及一个Engine，负责处理所有Connector所获得的客户请求。
3. Connector：一个Connector将在某个指定的端口上监听客户请求，并且将获得的请求交给Engine来处理，从Engine获得获得回应并且返
            回给客户。Tomcat有一个典型的Connector，一个直接监听来自browser的http请求，一个监听来自其他WebServer的请求。
            比如8080端口和8009端口就是做这两个事。
4. Engine：Engine下可以配置多个虚拟主机Virtual Host，每个虚拟主机都有一个域名，当Engine获得一个请求时，它把该请求匹配到某个        
            Host上，然后把该请求交给该Host来处理，Engine有一个默认虚拟主机，当请求无法匹配到任何一个Host上的时候，将交给该Host来        
            处理。
5. Host：代表一个虚拟主机，每个虚拟主机和某个网络域名Domain Name相匹配，每个虚拟主机下可以部署一个或者多个WebApp，每个
            WebApp对应一个Context，每个Context都有一个Context Path，当Host获得一个请求时，将把该请求匹配到某个Context上，然后
            把该请求交给该Context来处理。
6. Context：一个Context 对应于一个Web Application，一个Web Application 由一个或者多个Servlet组成，Context在创建的时候将根据        
            配置文件 $CATALINA_HOME/conf/web.xml和$WEBAPP_HOME/WEB-INF/web.xml载入Servlet类。

Tomcat Server处理一个http请求的过程
假设来自客户的请求为：
http://localhost:8080/wsota/wsota_index.jsp
1) 请求被发送到本机端口8080，被在那里侦听的Coyote HTTP/1.1 Connector获得
2) Connector把该请求交给它所在的Service的Engine来处理，并等待来自Engine的回应
3) Engine获得请求localhost/wsota/wsota_index.jsp，匹配它所拥有的所有虚拟主机Host
4) Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机）
5) localhost Host获得请求/wsota/wsota_index.jsp，匹配它所拥有的所有Context
6) Host匹配到路径为/wsota的Context（如果匹配不到就把该请求交给路径名为”"的Context去处理）
7) path=”/wsota”的Context获得请求/wsota_index.jsp，在它的mapping table中寻找对应的servlet
8) Context匹配到URL PATTERN为*.jsp的servlet，对应于JspServlet类
9) 构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet或doPost方法
10)Context把执行完了之后的HttpServletResponse对象返回给Host
11)Host把HttpServletResponse对象返回给Engine
12)Engine把HttpServletResponse对象返回给Connector
13)Connector把HttpServletResponse对象返回给客户browser

---------------------------------------------------------------
JVM:
JVM类加载机制：
类从被加载到虚拟机内存中开始，到卸载出内存为止，它的生命周期包括了：
加载(Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)、卸载(Unloading)七个阶段，
其中验证、准备、解析三个部分统称链接。
双亲委派模型:
Bootstrap ClassLoader(启动类加载器) <-- Extension ClassLoade(扩展类加载器) <-- Application ClassLoader(应用程序类加载器) <-- User ClassLoader

JVM内存模型：java堆，虚拟机栈，本地方法栈，方法区，程序计数器
堆区:   
1.存储的全部是对象，每个对象都包含一个与之对应的class的信息。(class的目的是得到操作指令)   
2.jvm只有一个堆区(heap)被所有线程共享，堆中不存放基本类型和对象引用，只存放对象本身   
栈区:   
1.每个线程包含一个栈区，栈中只保存基础数据类型的对象和自定义对象的引用(不是对象)，对象都存放在堆区中   
2.每个栈中的数据(原始类型和对象引用)都是私有的，其他栈不能访问。   
3.栈分为3个部分：基本类型变量区、执行环境上下文、操作指令区(存放操作指令)。   
方法区:   
1.又叫静态区，跟堆一样，被所有的线程共享。方法区包含所有的class和static变量。   
2.方法区中包含的都是在整个程序中永远唯一的元素，如class，static变量。   

java堆被划分成两个不同的区域：新生代 ( Young )、老年代 ( Old )。新生代 ( Young ) 又被划分为三个区域：Eden、From Survivor、To Survivor。
默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ( 该值可以通过参数 CXX:NewRatio 来指定 )，即：新生代 ( Young ) = 1/3 的堆空间大小。老年代 ( Old ) = 2/3 的堆空间大小。其中，新生代 ( Young ) 被细分为 Eden 和 两个 Survivor 区域，这两个 Survivor 区域分别被命名为 from 和 to，以示区分。
默认的，Edem : from : to = 8 : 1 : 1 ( 可以通过参数 CXX:SurvivorRatio 来设定 )，即： Eden = 8/10 的新生代空间大小，from = to = 1/10 的新生代空间大小。
JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。
因此，新生代实际可用的内存空间为 9/10 ( 即90% )的新生代空间。
(1)GC :强制立即回收垃圾，即释放内存(将对象所有引用赋值为Null，由GC自动回收)。 分为 Minor GC 和 Full GC(Major GC) 
GC收集垃圾的主要区域是堆，Minor GC是发生在新生代的垃圾收集动作，采用复制算法，Full GC是发生在老年代的垃圾回收动作，采用标记-清除算法。 
**新生代几乎是所有Java对象出生的地方，在Eden+一块survivor中出生，经过一次Minor GC后如果还存活，就被复制到另一块survivor中保存，并将年龄设为1，此后每经过一次Minor GC后年龄加1.当年龄到达某个值时就变为老年态。对于一些需要耗费大块连续内存区域时，直接进入老年态。新生代中的对象生命周期短，由GC来回收Eden+survivor中的内存。 
**老年代标记-清除算法收集垃圾的时候会产生许多的内存碎片 ( 即不连续的内存空间 )，此后需要为较大的对象分配内存空间时，若无法找到足够的连续的内存空间，就会提前触发一次 GC 的收集动作。

垃圾回收算法：
复制算法
标记-清除算法：产生内存碎片。
标记-整理算法
分代算法:新生代使用复制算法，老年代使用标记-整理算法。

JVM调优：

---------------------------------------------------------------
数据库优化：
在数据仓库项目中，由于数据规模庞大，提高数据的查询效率是永恒的主题，常见的优化手段有：
1、 硬件优化，提高机器性能，增加硬件等;
2、 优化查询语句，将限定性强的where条件放前，用exists代替in操作等;
3、 优化索引，建立有效的索引并检查和修复缺少的统计信息等;
4、 数据库系统文件优化，将数据文件、索引文件、日志文件放置在不同的磁盘上，提高并行度等

除了以上方法外，还有一种很重要但易被大家忽略的方法：大表数据分割。
当一个表的数据规模达到数亿条时，索引已基本发挥不了作用:建立索引要花费大量时间，查询时由于要扫描大的索引表也要花费大量时间。
为了发挥索引的作用，可以将大表按照某个字段拆分为若干个小表。

例如，国内某大型保险公司，其有36家分公司，一年的保单明细表(f_policy)大概有2亿条记录,两年的数据超过4亿条，
如果在f_policy上作一次查询，响应非常慢，可以考虑将f_policy按照机构拆分为36个同构的小表，在作整个保单明细表的查询时，
可以使用union all操作合并数据，或者建立一个union all的视图，查询效率大大提高。并且，作这样的拆分非常有用，
因为经常会有只查询某个分公司数据的需求。


1NF:没有重复的组或多值的列，这是数据库设计的最低要求。
2NF:每个非关键字段必须依赖于主关键字，不能依赖于一个组合式主关键字的某些组成部分。消除部分依赖，大部分情况下，数据库设计都应该达到第二范式。
3NF:一个非关键字段不能依赖于另一个非关键字段。消除传递依赖。



---------------------------------------------------------------
spring:
一：spring基本概念
1）struts2是web框架，hibernate是orm框架
2）spring是容器框架，创建bean，维护bean之间的关系
3）spring可以管理web层，持久层，业务层，dao层，spring可以配置各个层的组件，并且维护各个层的关系

二：spring核心原理
1.IOC控制反转
概念：控制权由对象本身转向容器，由容器根据配置文件创建对象实例并实现各个对象的依赖关系。
核心：bean工厂

2.AOP面向切面编程
a.静态代理
根据每个具体类分别编写代理类
根据一个接口编写一个代理类
b.动态代理
针对一个方面编写一个InvocationHandler，然后借用JDK反射包中的Proxy类为各种接口动态生成相应的代理类

1. Spring是什么？讲一下Spring的由来、思想、特性
2. Spring都有哪些产品组成？每个产品的作用、特点、使用场景？
3. 我在工作中用到了Spring的哪些产品、哪些特性？怎么用的？为什么用？

为什么使用Spring 
1：降低组件之间的耦合度，实现各层之间的解耦 
2：可以使用容器提供的众多服务。如： 
--事务管理服务 
--JMS 
--Spring core核心服务 
--持久化服务 
--其他 
3：提供了单例模式支持。开发人员不需要自己编写实现代码 
4：提供了AOP技术。实现如：权限拦截，运行监控等功能 
5：提供了众多的辅助类。如JDBC Template，HIbernate Template 
6：对主流的应用框架提供了集成支持。集成Struts，JPA，Hibernate



---------------------------------------------------------------
String str=new String("123");   紧接着这段代码之后的往往是这个问题，那就是这行代码究竟创建了几个String对象呢？  
相信大家对这道题并不陌生，答案也是众所周知的，2个。  
我们可以把上面这行代码分成String str、=、"123"和new String()四部分来看待。String str只是定义了一个名为str的String类型的变量，
因此它并没有创建对象；=是对变量str进行初始化，将某个对象的引用（或者叫句柄）赋值给它，显然也没有创建对象；
现在只剩下new String("123")了。那么，new String("123")为什么又能被看成"123"和new String()呢？  

String a = new String("ab");
String b = new String("ab");
String c = "ab";
String d = "a" + "b";
String e = "b";
String f = "a" + e;
System.out.println(b.intern() == a);
System.out.println(b.intern() == c);
System.out.println(b.intern() == d);
System.out.println(b.intern() == f);
System.out.println(b.intern() == a.intern());
运行结果：
false
true
true
false
true
intern()表示取字符串池的字符串。

------------------------------------------------------------------
设计模式：

单例模式：

观察者模式：

责任链模式：

抽象工厂模式：
工厂方法模式： 一个抽象产品类，可以派生出多个具体产品类。 一个抽象工厂类，可以派生出多个具体工厂类。 每个具体工厂类只能创建一个具体产品类的实例。
 抽象工厂模式： 多个抽象产品类，每个抽象产品类可以派生出多个具体产品类。 一个抽象工厂类，可以派生出多个具体工厂类。 每个具体工厂类可以创建多个具体产品类的实例。
 区别： 工厂方法模式只有一个抽象产品类，而抽象工厂模式有多个。 工厂方法模式的具体工厂类只能创建一个具体产品类的实例，而抽象工厂模式可以创建多个。



------------------------------------------------------------------
TCP/IP协议:TCP/IP协议按照层次分为以下四层:应用层、传输层、网络层、数据链路层。
http协议
ftp:文件传输协议
DNS：域名系统

网络七层协议：应用层（FTP，DNS，HTTP协议）--表示层--会话层--传输层（TCP，UDP）--网络层（数据包）--数据链路层（网卡，光纤）--物理层

IP协议：IP(Internet protocol),这里的IP不是值得我们通常所说的192.168.1.1.这个IP指的是一种协议，而后面的数字值得是IP地址。
IP协议的作用在于把各种数据包准确无误的传递给对方，其中两个重要的条件是IP地址，和MAC地址（Media Access Control Address）。
由于IP地址是稀有资源，不可能每个人都拥有一个IP地址，所以我们通常的IP地址是路由器给我们生成的IP地址，
路由器里面会记录我们的MAC地址。而MAC地址是全球唯一的，除去人为因素外不可能重复。举一个现实生活中的例子，
IP地址就如同是我们居住小区的地址，而MAC地址就是我们住的那栋楼那个房间那个人。

ip协议的职责：搜索对方的地址，一边中转一边传送。

所谓的字节流服务（Byte Stream Service）是指，为了方便传输，将大块数据分割成以报文段（segment）为单位的数据包进行管理。
而可靠的传输服务是指，能够把数据准确可靠地传给对方。一言以蔽之，TCP 协议为了更容易传送大数据才把数据分割，而且 TCP 协议能够确认数据最终是否送达到对方。
为了确保信息能够确保准确无误的到达，TCP采用了著名的三次握手策略（three-way handshaking）.
------------------------------------------------------------------
Socket编程：
IP地址+端口号组成了所谓的Socket，Socket是网络上运行的程序之间双向通信链路的终结点，是TCP和UDP的基础
Socket套接字：
 网络上具有唯一标识的IP地址和端口组合在一起才能构成唯一能识别的标识符套接字。
Socket原理机制：
    通信的两端都有Socket
    网络通信其实就是Socket间的通信
    数据在两个Socket间通过IO传输 


------------------------------------------------------------------
https交互流程
1)    客户端请求建立SSL连接，并将自己支持的一套加密规则发送给网站。
2)    网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息
3)    获得网站证书之后浏览器要做以下工作：
  验证证书的合法性
  如果证书受信任，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。
  使用约定好的HASH计算握手消息，
  使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。
4)    网站接收浏览器发来的数据之后要做以下的操作：
  使用自己的私钥将信息解密取出密码
  使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。
  使用密码加密一段握手消息，发送给浏览器
5)    浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手结束。
6)    使用随机密码和对称加密算法对传输的数据加密，传输。

HTTP与HTTPS的区别：
1)     https协议需要申请证书。
2)     http是超文本传输协议，明文传输；https使用的是具有安全性的SSL加密传输协议。
3)     http端口80,；https端口443。
4)     http连接简单无状态；https由SSL+HTTP协议构件的可进行加密传输、身份验证的网络协议。

------------------------------------------------------------------
与对称加密算法不同，非对称加密算法需要两个密钥：公开密钥（publickey）和私有密钥（privatekey）。公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。
------------------------------------------------------------------
数据库挂了有什么应急方式

------------------------------------------------------------------
http://ifeve.com/disruptor/
Disruptor它是一个开源的并发框架，并获得2011 Duke’s 程序框架创新奖，能够在无锁的情况下实现网络的Queue并发操作。
disruptor以内存为中心辅以持久化的日志（而不是持久化的数据库辅以内存缓存）的架构设计.
该架构主要基于：Disruptor + In Memory DDD + Event Sourcing
1.通过高并发框架（Disruptor）实现用户事件的输入和Domain Event的输出；
2.一个常驻内存的Business Logic Processor（DDD领域模型），它负责在纯内存中处理业务逻辑；关键点：首先确保用户输入事件被持久化到数据库，并定时创建快照，然后在内存中响应事件更改业务对象的状态；因为一切都是在内存中处理，所以没有IO，也不需要数据库事务，非常快；
3.机器down了怎么办？因为我们首先确保了业务对象的任何状态改变之前先持久化用户输入事件，所以在down机的时候通过事件回溯重新得到最新的业务对象。因为有了快照的保存，所以重建对象也非常快；

提出新的并发模型，每个CPU一个线程，多个CPU多个线程并发模式，摒弃了锁模式。

线程读写资源在不用锁的情况下高效实现(高并发情况下怎样尽量实现无锁编程):
一个在线2k的游戏，每秒钟并发都吓死人。传统的hibernate直接插库基本上是不可行的。我就一步步推导出一个无锁的数据库操作。
　　1. 并发中如何无锁。
　　一个很简单的思路，把并发转化成为单线程。Java的Disruptor就是一个很好的例子。如果用java的concurrentCollection类去做，原理就是启动一个线程，跑一个Queue，并发的时候，任务压入Queue，线程轮训读取这个Queue，然后一个个顺序执行。
　　在这个设计模式下，任何并发都会变成了单线程操作，而且速度非常快。现在的node.js, 或者比较普通的ARPG服务端都是这个设计，“大循环”架构。
　　这样，我们原来的系统就有了2个环境：并发环境 + ”大循环“环境
　　并发环境就是我们传统的有锁环境，性能低下。
　　”大循环“环境是我们使用Disruptor开辟出来的单线程无锁环境，性能强大。
　　
　　2. ”大循环“环境 中如何提升处理性能。
　　一旦并发转成单线程，那么其中一个线程一旦出现性能问题，必然整个处理都会放慢。所以在单线程中的任何操作绝对不能涉及到IO处理。那数据库操作怎么办？
　　增加缓存。这个思路很简单，直接从内存读取，必然会快。至于写、更新操作，采用类似的思路，把操作提交给一个Queue，然后单独跑一个Thread去一个个获取插库。这样保证了“大循环”中不涉及到IO操作。
　　
　　问题再次出现：
　　如果我们的游戏只有个大循环还容易解决，因为里面提供了完美的同步无锁。
　　但是实际上的游戏环境是并发和“大循环”并存的，即上文的2种环境。那么无论我们怎么设计，必然会发现在缓存这块上要出现锁。
　　
　　3. 并发与“大循环”如何共处，消除锁？
　　我们知道如果在“大循环”中要避免锁操作，那么就用“异步”，把操作交给线程处理。结合这2个特点，我稍微改下数据库架构。
　　原本的缓存层，必然会存在着锁，例如：
　　public TableCache
　　{
　　private HashMap<String, Object> caches = new ConcurrentHashMap<String, Object>();
　　}
　　这个结构是必然的了，保证了在并发的环境下能够准确的操作缓存。但是”大循环“却不能直接操作这个缓存进行修改，所以必须启动一个线程去更新缓存，例如：
　　private static final ExecutorService EXECUTOR = Executors.newSingleThreadExecutor();
　　EXECUTOR.execute(new LatencyProcessor(logs));
　　class LatencyProcessor implements Runnable
　　{
　　public void run()
　　{
　　// 这里可以任意的去修改内存数据。采用了异步。
　　}
　　}
　　OK，看起来很漂亮。但是又有个问题出现了。在高速存取的过程中，非常有可能缓存还没有被更新，就被其他请求再次获取，得到了旧的数据。
　　
　　4. 如何保证并发环境下缓存数据的唯一正确？
　　我们知道，如果只有读操作，没有写操作，那么这个行为是不需要加锁的。
　　我使用这个技巧，在缓存的上层，再加一层缓存，成为”一级缓存“，原来的就自然成为”二级缓存“。有点像CPU了对不？
　　一级缓存只能被”大循环“修改，但是可以被并发、”大循环“同时获取，所以是不需要锁的。
　　当发生数据库变动，分2种情况：
　　1）并发环境下的数据库变动，我们是允许有锁的存在，所以直接操作二级缓存，没有问题。
　　2）”大循环“环境下数据库变动，首先我们把变动数据存储在一级缓存，然后交给异步修正二级缓存，修正后删除一级缓存。
　　这样，无论在哪个环境下读取数据，首先判断一级缓存，没有再判断二级缓存。
　　这个架构就保证了内存数据的绝对准确。
　　而且重要的是：我们有了一个高效的无锁空间，去实现我们任意的业务逻辑。
　　
　　最后，还有一些小技巧提升性能。
　　1. 既然我们的数据库操作已经被异步处理，那么某个时间，需要插库的数据可能很多，通过对表、主键、操作类型的排序，我们可以删除一些无效操作。例如：
　　a）同一个表同一个主键的多次UPdate，取最后一次。
　　b）同一个表同一个主键，只要出现Delete，前面所有操作无效。
　　2. 既然我们要对操作排序，必然会存在一个根据时间排序，如何保证无锁呢？使用
　　private final static AtomicLong _seq = new AtomicLong(0);
　　即可保证无锁又全局唯一自增，作为时间序列。

------------------------------------------------------------------------------------
常见并发同步案例分析

    案例一:订票系统案例，某航班只有一张机票，假定有1w个人打开你的网站来订票，问你如何解决并发问题(可扩展到任何高并发网站要考虑

               的并发读写问题)

    问题，1w个人来访问，票没出去前要保证大家都能看到有票，不可能一个人在看到票的时候别人就不能看了。到底谁能抢到，那得看这个人的“运气”（网

             络快慢等）

其次考虑的问题，并发，1w个人同时点击购买，到底谁能成交？总共只有一张票。

首先我们容易想到和并发相关的几个方案 ：

锁同步同步更多指的是应用程序的层面，多个线程进来，只能一个一个的访问，java中指的是syncrinized关键字。锁也有2个层面，一个是java中谈到的对

象锁，用于线程同步；另外一个层面是数据库的锁；如果是分布式的系统，显然只能利用数据库端的锁来实现。

假定我们采用了同步机制或者数据库物理锁机制，如何保证1w个人还能同时看到有票，显然会牺牲性能，在高并发网站中是不可取的。使用hibernate后我们

提出了另外一个概念：乐观锁、悲观锁（即传统的物理锁）；

采用乐观锁即可解决此问题。乐观锁意思是不锁定表的情况下，利用业务的控制来解决并发问题，这样即保证数据的并发可读性又保证保存数据的排他性，保

证性能的同时解决了并发带来的脏数据问题。

hibernate中如何实现乐观锁：

前提：在现有表当中增加一个冗余字段，version版本号, long类型

原理：

1）只有当前版本号》=数据库表版本号，才能提交

2）提交成功后，版本号version ++

实现很简单：在ormapping增加一属性optimistic-lock="version"即可，以下是样例片段

<hibernate-mapping>

<class name="com.insigma.stock.ABC" optimistic-lock="version" table="T_Stock" schema="STOCK">

案例二、股票交易系统、银行系统，大数据量你是如何考虑的

首先，股票交易系统的行情表，每几秒钟就有一个行情记录产生，一天下来就有（假定行情3秒一个） 股票数量×20×60*6 条记录，一月下来这个表记录数

量多大？ oracle中一张表的记录数超过100w后 查询性能就很差了，如何保证系统性能？

再比如，中国移动有上亿的用户量，表如何设计？把所有用于存在于一个表么？

所以，大数量的系统，必须考虑表拆分-（表名字不一样，但是结构完全一样），通用的几种方式：（视情况而定）

1）按业务分，比如 手机号的表，我们可以考虑 130开头的作为一个表，131开头的另外一张表 以此类推

2）利用oracle的表拆分机制做分表

3）如果是交易系统，我们可以考虑按时间轴拆分，当日数据一个表，历史数据弄到其它表。这里历史数据的报表和查询不会影响当日交易。

当然，表拆分后我们的应用得做相应的适配。单纯的or-mapping也许就得改动了。比如部分业务得通过存储过程等

此外，我们还得考虑缓存

这里的缓存，指的不仅仅是hibernate，hibernate本身提供了一级二级缓存。这里的缓存独立于应用，依然是内存的读取，假如我们能减少数据库频繁的访

问，那对系统肯定大大有利的。比如一个电子商务系统的商品搜索，如果某个关键字的商品经常被搜，那就可以考虑这部分商品列表存放到缓存（内存中

去），这样不用每次访问数据库，性能大大增加。

简单的缓存大家可以理解为自己做一个hashmap，把常访问的数据做一个key，value是第一次从数据库搜索出来的值，下次访问就可以从map里读取，而不

读数据库；专业些的目前有独立的缓存框架比如memcached 等，可独立部署成一个缓存服务器。

 

常见的提高高并发下访问的效率的手段

      首先要了解高并发的的瓶颈在哪里？

     1、可能是服务器网络带宽不够

     2.可能web线程连接数不够

     3.可能数据库连接查询上不去。

     根据不同的情况，解决思路也不同。

像第一种情况可以增加网络带宽，DNS域名解析分发多台服务器。

负载均衡，前置代理服务器nginx、apache等等

数据库查询优化，读写分离，分表等等

   最后复制一些在高并发下面需要常常需要处理的内容:

尽量使用缓存，包括用户缓存，信息缓存等，多花点内存来做缓存，可以大量减少与数据库的交互，提高性能。

用jprofiler等工具找出性能瓶颈，减少额外的开销。

优化数据库查询语句，减少直接使用hibernate等工具的直接生成语句（仅耗时较长的查询做优化）。

优化数据库结构，多做索引，提高查询效率。

统计的功能尽量做缓存，或按每天一统计或定时统计相关报表，避免需要时进行统计的功能。

能使用静态页面的地方尽量使用，减少容器的解析（尽量将动态内容生成静态html来显示）。

解决以上问题后，使用服务器集群来解决单台的瓶颈问题。

--------------------------------------------------------------
MySQL升级:
1. 下载并安装好新版本的MySQL数据库，并将其端口改为3307（避免和旧版本的3306冲突），启动服务。

2. 在新版本下创建同名数据库。

# mysqldump -p3307 -uroot create mysqlsystems_com

3. 在旧版本下备份该数据库。

# mysqldump -p3306 -uroot mysqlsystems_com > mysqlsystems_com.bk

Note: 你也可以加上Copt选项，这样可以使用优化方式将你的数据库导出，减少未知的问题。

4. 将导出的数据库备份导入到新版本的MySQL数据库中。

# mysql -p3307 -uroot mysqlsystems_com < mysqlsystems_com.bk

5. 再将旧版本数据库中的data目录下的mysql数据库全部覆盖到新版本中。

# cp -R /opt/mysql-5.1/data/mysql /opt/mysql-5.4/data

Note: 大家也都知道这个默认数据库的重要性。

6. 在新版下执行mysql_upgrade命令，其实这个命令包含一下三个命令：
# mysqlcheck Ccheck-upgrade Call-databases Cauto-repair
# mysql_fix_privilege_tables
# mysqlcheck Call-databases Ccheck-upgrade Cfix-db-names Cfix-table-names

Note: 在每一次的升级过程中，mysql_upgrade这个命令我们都应该去执行，它通过mysqlcheck命令帮我们去检查表是否兼容新版本的数据库同时作出修复，还有个很重要的作用就是使用mysql_fix_privilege_tables命令去升级权限表。

7. 关闭旧版本，将新版的数据库的使用端口改为3306，重新启动新版本MySQL数据库。到此，一个简单环境下的数据库升级就结束了。


--------------------------------------------------------------
2017一季度JAVA面试题锦集:
1、如何实现分布式事务，你们公司是怎么解决的？
目前比较多的解决方案有几个：
一、结合MQ消息中间件实现的可靠消息最终一致性
二、TCC补偿性事务解决方案
三、最大努力通知型方案
第一种方案：可靠消息最终一致性，需要业务系统结合MQ消息中间件实现，在实现过程中需要保证消息的成功发送及成功消费。即需要通过业务系统控制MQ的消息状态
第二种方案：TCC补偿性，分为三个阶段TRYING-CONFIRMING-CANCELING。每个阶段做不同的处理。
TRYING阶段主要是对业务系统进行检测及资源预留
CONFIRMING阶段是做业务提交，通过TRYING阶段执行成功后，再执行该阶段。默认如果TRYING阶段执行成功，CONFIRMING就一定能成功。
CANCELING阶段是回对业务做回滚，在TRYING阶段中，如果存在分支事务TRYING失败，则需要调用CANCELING将已预留的资源进行释放。
第三种方案：最大努力通知型，这种方案主要用在与第三方系统通讯时，比如：调用微信或支付宝支付后的支付结果通知。这种方案也是结合MQ进行实现，例如：通过MQ发送http请求，设置最大通知次数。达到通知次数后即不再通知。


--------------------------------
2、HashMap数据结构及实现原理，其链表是用来解决什么问题的
数组：存储区间连续，占用内存严重，寻址容易，插入删除困难
链表：存储区间离散，占用内存比较宽松，寻址困难，插入删除容易
hashmap综合应用了这两种数据结构，实现了寻址容易，插入删除也容易
实现原理：用一个数组来存储元素，但是这个数组存储的不是基本数据类型。HashMap实现巧妙的地方就在这里，数组存储的元素是一个Entry类，这个类有三个数据域，key、value（键值对），next(指向下一个Entry)
--------------------------------
3、可以自定义java.lang.String类吗，说明为什么
   可以，但是即使你写了这个类，也没有用.
   因加载某个类时，优先使用父类加载器加载需要使用的类。如果我们自定义了java.lang.String这个类，
加载该自定义的String类，该自定义String类使用的加载器是AppClassLoader，根据优先使用父类加载器原理，
AppClassLoader加载器的父类为ExtClassLoader，所以这时加载String使用的类加载器是ExtClassLoader，
但是类加载器ExtClassLoader在jre/lib/ext目录下没有找到String.class类。然后使用ExtClassLoader父类的加载器BootStrap，
父类加载器BootStrap在JRE/lib目录的rt.jar找到了String.class，将其加载到内存中。这就是类加载器的委托机制。
--------------------------------
4、redis
1）有哪几种类型的数据结构
一共有5种数据结构,
String――字符串
Hash――字典
List――列表
Set――集合
Sorted Set――有序集合

2）如何防止缓存穿透
缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。
解决办法：
1.对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃。还有最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
2.也可以采用一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
缓存雪崩
如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。
这个没有完美解决办法，但可以分析用户行为，尽量让失效时间点均匀分布。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。
解决办法：
1.在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。
2.可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存
3.不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀
4.做二级缓存，或者双缓存策略。A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。


3）如何做集群，有哪些方案
4）和memcache、ehcache有什么区别
memcache比redis快
redis比memcache稳定，有持久化机制，支持更多的数据类型

5）如何做持久化
--------------------------------
5、如何防止死锁
1.加锁顺序
如果能确保所有的线程都是按照相同的顺序获得锁，那么死锁就不会发生。按照顺序加锁是一种有效的死锁预防机制。但是，这种方式需要你事先知道所有可能会用到的锁(译者注：并对这些锁做适当的排序)，但总有些时候是无法预知的。
2.加锁时限
在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试。
3.死锁检测
死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。
当一个线程请求锁失败时，这个线程可以遍历锁的关系图看看是否有死锁发生。例如，线程A请求锁7，但是锁7这个时候被线程B持有，这时线程A就可以检查一下线程B是否已经请求了线程A当前所持有的锁。如果线程B确实有这样的请求，那么就是发生了死锁（线程A拥有锁1，请求锁7；线程B拥有锁7，请求锁1）。
当然，死锁一般要比两个线程互相持有对方的锁这种情况要复杂的多。线程A等待线程B，线程B等待线程C，线程C等待线程D，线程D又在等待线程A。线程A为了检测死锁，它需要递进地检测所有被B请求的锁。从线程B所请求的锁开始，线程A找到了线程C，然后又找到了线程D，发现线程D请求的锁被线程A自己持有着。这是它就知道发生了死锁。
一个可行的做法是释放所有锁，回退，并且等待一段随机的时间后重试。这个和简单的加锁超时类似，不一样的是只有死锁已经发生了才回退，而不会是因为加锁的请求超时了。虽然有回退和等待，但是如果有大量的线程竞争同一批锁，它们还是会重复地死锁（编者注：原因同超时类似，不能从根本上减轻竞争）。
一个更好的方案是给这些线程设置优先级，让一个（或几个）线程回退，剩下的线程就像没发生死锁一样继续保持着它们需要的锁。如果赋予这些线程的优先级是固定不变的，同一批线程总是会拥有更高的优先级。为避免这个问题，可以在死锁发生的时候设置随机的优先级。

--------------------------------
6、zookeeper
1）说说选举算法
2）有哪几种节点类型
3）有哪些应用场景
4）如何部署集群，至少有几台机器？
--------------------------------
7、dubbo
1）里面用的什么通信框架
2）和dubbox有什么区别
3）里面用的什么序列化框架
4）如何利用zookeeper实现注册发现的，还有别的方式实现注册发现吗
5）还了解别的分布式框架吗
6）如何解决分布式服务调用链过长的问题
7）它是阻塞的吗
8）说说核心的配置有哪些
--------------------------------
8、线程同步的有哪些方式
--------------------------------
9、说说你们公司的架构并画出来
--------------------------------
10、springmvc加载流程
--------------------------------
11、nginx有哪几种负载均衡算法
--------------------------------
12、mysql
1）如何进行sql优化？如何进行性能检测
2）有哪几种索引类型及应用场景
3）主备同步是如何进行的，原理是什么
4）分库分表有哪几种分法，如何解决数据分布不均匀的问题，如果避免查询某个字段扫全库全表的情况
5）事务隔离级别有哪几种，默认是哪个
6）如何解决幻读问题
7）读写分离方案
8）有哪几种引擎及应用场景
--------------------------------
13、mybatis占位符的#和$有什么区别
--------------------------------
14、如何实现分布锁，需要考虑的问题
--------------------------------
15、spring事务传播机制有哪些，如何用jdbc实现require_new
--------------------------------
16、java集合常用类及数据结构
--------------------------------
17、MQ
1）什么是推模式，什么是拉模式
2）有没有消息丢失情况，如何防止
3）MQ用来解决什么问题
4）你们用的什么MQ，为什么要用这个，它的最大吞吐量是多少
--------------------------------
18、设计模式
1）说说六大设计原则
2）你会哪些设计模式
3）装饰模式和代理模式有什么区别
4）单例模式有哪几种写法，有哪些注意的地方
5）怎么实现策略模式
6）spring中用到了哪些设计模式
--------------------------------
19、线程有哪几种状态流转
--------------------------------
20、spring ioc aop是什么，实现动态代理有哪些方式，代理类和原来的类之间是什么关系
--------------------------------
21、什么是悲观锁和乐观锁，分别如何实现

乐观锁，就是在数据库设计一个版本号的字段，每次修改都使其+1，这样在提交时比对提交前的版本号就知道是不是并发提交了，但是有个缺点就是只能是应中控制，如果有跨应用修改同一条数据乐观锁就没办法了，这个时候可以考虑悲观锁。
悲观锁，就是直接在数据库层面将数据锁死，类似于oralce中使用select xxxxx from xxxx where xx=xx for update，这样其他线程将无法提交数据。
--------------------------------
22、java有哪几种自带的线程池，说说它们的应用场景
Java通过Executors提供四种线程池，分别为：
newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

--------------------------------
23、说说volatile关键字及使用场景


volatile 只能保证 “可见性”，不能保证 “原子性”。
count++; 这条语句由3条指令组成：    
（1）将 count 的值从内存加载到 cpu 的某个寄存器r    
（2）将 寄存器r 的值 +1，结果存放在 寄存器s    
（3）将 寄存器s 中的值写回内存
所以，如果有多个线程同时在执行 count++;，在某个线程执行完第（3）步之前，其它线程是看不到它的执行结果的。
在没有 volatile 的时候，执行完 count++;，执行结果其实是写到CPU缓存中，没有马上写回到内存中，后续在某些情况下（比如CPU缓存不够用）再将CPU缓存中的值flush到内存。
正因为没有马上写到内存，所以不能保证其它线程可以及时见到执行的结果。在有 volatile 的时候，执行完 count++;，执行结果写到CPU缓存中，并且同时写回到内存，
因为已经写回内存了，所以可以保证其它线程马上看到执行的结果。但是，volatile 并没有保证原子性，在某个线程执行（1）（2）（3）的时候，volatile 并没有锁定 count 的值，
也就是并不能阻塞其他线程也执行（1）（2）（3）。可能有两个线程同时执行（1），所以（2）计算出来一样的结果，然后（3）存回的也是同一个值。

应用场景: 多线程下你不在乎volatile变量的值是什么，只在乎它有没有变化的场景 
可以用volatile的地方：对一个变量，更新其值的时候不依赖于当前值，且该变量不会和其他一起构成一个不可变条件。
--------------------------------
24、怎么排查多线程问题
--------------------------------
25、session共享有哪些方案
1.基于数据库的Session共享
首选当然是大名鼎鼎的MySQL数据库，并且建议使用内存表Heap，提高session操作的读写效率。这个方案的实用性比较强，相信大家普遍在使用，它的缺点在于session的并发读写能力取决于Mysql数据库的性能，同时需要自己实现session淘汰逻辑，以便定时从数据表中更新、删除 session记录，当并发过高时容易出现表锁，虽然我们可以选择行级锁的表引擎，但不得不否认使用数据库存储Session还是有些杀鸡用牛刀的架势。
2. 基于Cookie的Session共享
这个方案我们可能比较陌生，但它在大型网站中还是比较普遍被使用。原理是将全站用户的Session信息加密、序列化后以Cookie的方式，统一种植在根域名下（如：.host.com），利用浏览器访问该根域名下的所有二级域名站点时，会传递与之域名对应的所有Cookie内容的特性，从而实现用户的Cookie化Session 在多服务间的共享访问。
这个方案的优点无需额外的服务器资源；缺点是由于受http协议头信心长度的限制，仅能够存储小部分的用户信息，同时Cookie化的 Session内容需要进行安全加解密（如：采用DES、RSA等进行明文加解密；再由MD5、SHA-1等算法进行防伪认证），另外它也会占用一定的带宽资源，因为浏览器会在请求当前域名下任何资源时将本地Cookie附加在http头中传递到服务器。
3. 基于缓存(Memcache)的Session共享
Memcache由于是一款基于Libevent多路异步I/O技术的内存共享系统，简单的Key + Value数据存储模式使得代码逻辑小巧高效，因此在并发处理能力上占据了绝对优势，目前本人所经历的项目达到2000/秒 平均查询，并且服务器CPU消耗依然不到10%。
另外值得一提的是Memcache的内存hash表所特有的Expires数据过期淘汰机制，正好和Session的过期机制不谋而合，降低了过期Session数据删除的代码复杂度，对比“基于数据库的存储方案”，仅这块逻辑就给数据表产生巨大的查询压力。
4. session复制

--------------------------------
26、jvm有哪些自带命令及如何使用
--------------------------------
27、说说jvm内存模式及如何调优
--------------------------------
28、如何对tomcat调优
Tomcat 优化分为：系统优化、Java虚拟机调优、Tomcat本身的优化。
一、调整tomcat的占用内存
将JAVA_OPTS="-Xms 1024m CXmx 1520m"一行的两个参数依据服务器实际内存数量分别进行更改：
        - Xms为tomcat启动初始内存，一般为服务器开机后可用空闲内存减去100M
        - Xmx为tomcat最大占用内存，一般为服务器开机后可用空闲内存减去50M
一般说来，您应该使用物理内存的 80% 作为堆大小。
二、调整tomcat的线程参数
编辑tomcat安装目录下的conf目录下的server.xml文件
在tomcat配置文件server.xml中的<Connector />配置中，和连接数相关的参数有：
maxThreads="150"     表示最多同时处理150个连接,Tomcat使用线程来处理接收的每个请求。这个值表示Tomcat可创建的最大的线程数。默认值200。   
minSpareThreads="25"     表示即使没有人使用也开这么多空线程等待  
  maxSpareThreads="75"     表示如果最多可以空75个线程，例如某时刻有80人访问，之后没有人访问了，则tomcat不会保留80个空线程，而是关闭5个空的。  （一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。默认值50。 
）
   
  acceptCount="100"   当同时连接的人数达到maxThreads时，还可以接收排队的连接数量，超过这个连接的则直接返回拒绝连接。（指定当任何能够使用的处理请求的线程数都被使用时，能够放到处理队列中的请求数，超过这个数的请求将不予处理。默认值100。 ）
其中和最大连接数相关的参数为maxThreads和acceptCount。如果要加大并发连接数，应同时加大这两个参数。
web server允许的最大连接数还受制于操作系统的内核参数设置，通常Windows是2000个左右，Linux是1000个左右。tomcat5中的配置示例：
    <Connector port="8080"
               maxThreads="150" minSpareThreads="25" maxSpareThreads="75"
               acceptCount="100"/>
主要是调整maxThreads 和acceptCount的值
enableLookups： 
是否反查域名，默认值为true。为了提高处理能力，应配置为false 
connnectionTimeout： 
网络连接超时，默认值60000，单位：毫秒。配置为0表示永不超时，这样配置有隐患的。通常可配置为30000毫秒。

三、指定使用线程池来处理HTTP请求
首先要配置一个线程池来处理请求（与Connector是平级的，多个Connector可以使用同一个线程池来处理请求） 
<Executor name="tomcatThreadPool" namePrefix="catalina-exec-" 
maxThreads="1000" minSpareThreads="50" maxIdleTime="600000"/> 
<Connector port="8080"	
executor="tomcatThreadPool"	指定使用的线程池 
四、其它常用设置 
maxHttpHeaderSize="8192"	http请求头信息的最大程度，超过此长度的部分不予处理。一般8K。 
URIEncoding="UTF-8"	指定Tomcat容器的URL编码格式。 
disableUploadTimeout="true"	上传时是否使用超时机制 
enableLookups="false"--是否反查域名，默认值为true。为了提高处理能力，应设置为false 
compression="on"   打开压缩功能 
compressionMinSize="10240"	启用压缩的输出内容大小，默认为2KB 
noCompressionUserAgents="gozilla, traviata"   对于以下的浏览器，不启用压缩 
compressableMimeType="text/html,text/xml,text/javascript,text/css,text/plain" 哪些资源类型需要压缩 

五、配置示例 
<Connector port="8080" 
redirectPort="8443"	
maxThreads="150" 
minSpareThreads="25" 
maxSpareThreads="75" 
acceptCount="100" 
connectionTimeout="20000" 
protocol="HTTP/1.1" 

maxHttpHeaderSize="8192" 
URIEncoding="UTF-8" 
disableUploadTimeout="true" 
enableLookups="false" 
compression="on" 
compressionMinSize="10240" 
noCompressionUserAgents="gozilla, traviata" 
compressableMimeType="text/html,text/xml,text/javascript,text/css,text/plain"> 
... 
</Connector>
--------------------------------
29、用户登录有哪些保障安全的手段

关于用户输入密码错误问题可以提供一个解决方案：
第一次登陆时不用验证码 如果登陆出错 继续登陆就用户输入验证码
这样做有两个原因：1.如果是人为登陆 他就算是在试探密码 给出 输入也很慢 用户账户是安全的 
2.如果是恶意程序 它不能识别验证码 用户账户是安全的 


--------------------------------
30、如何减库存，如何防止超买超卖
一、秒杀带来了什么？
    秒杀或抢购活动一般会经过【预约】【抢订单】【支付】这3个大环节，而其中【抢订单】这个环节是最考验业务提供方的抗压能力的。
　　抢订单环节一般会带来2个问题：
　　1、高并发
　　比较火热的秒杀在线人数都是10w起的，如此之高的在线人数对于网站架构从前到后都是一种考验。
　　2、超卖
　　任何商品都会有数量上限，如何避免成功下订单买到商品的人数不超过商品数量的上限，这是每个抢购活动都要面临的难题。
二、如何解决？
首先，产品解决方案我们就不予讨论了。我们只讨论技术解决方案
1、前端
　　面对高并发的抢购活动，前端常用的三板斧是【扩容】【静态化】【限流】
　　A：扩容
　　加机器，这是最简单的方法，通过增加前端池的整体承载量来抗峰值。
　　B：静态化
　　将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。
　　C：限流
　　一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。
　　或者活动入口的时候增加游戏或者问题环节进行消峰操作。
　　D：有损服务
　　最后一招，在接近前端池承载能力的水位上限的时候，随机拒绝部分请求来保护活动整体的可用性。
 
2、后端
　　那么后端的数据库在高并发和超卖下会遇到什么问题呢？主要会有如下3个问题：（主要讨论写的问题，读的问题通过增加cache可以很容易的解决）
　　I：　首先MySQL自身对于高并发的处理性能就会出现问题，一般来说，MySQL的处理性能会随着并发thread上升而上升，但是到了一定的并发度之后会出现明显的拐点，之后一路下降，最终甚至会比单thread的性能还要差。
　　II： 其次，超卖的根结在于减库存操作是一个事务操作，需要先select，然后insert，最后update -1。最后这个-1操作是不能出现负数的，但是当多用户在有库存的情况下并发操作，出现负数这是无法避免的。
　　III：最后，当减库存和高并发碰到一起的时候，由于操作的库存数目在同一行，就会出现争抢InnoDB行锁的问题，导致出现互相等待甚至死锁，从而大大降低MySQL的处理性能，最终导致前端页面出现超时异常。

　　针对上述问题，如何解决呢？ 我们先看眼淘宝的高大上解决方案：
　　I：  关闭死锁检测，提高并发处理性能。
　　II：修改源代码，将排队提到进入引擎层前，降低引擎层面的并发度。
　　III：组提交，降低server和引擎的交互次数，降低IO消耗。
　　以上内容可以参考丁奇在DTCC2013上分享的《秒杀场景下MySQL的低效》一文。在文中所有优化都使用后，TPS在高并发下，从原始的150飙升到8.5w，提升近566倍，非常吓人！！！
　　不过结合我们的实际，改源码这种高大上的解决方案显然有那么一点不切实际。于是小伙伴们需要讨论出一种适合我们实际情况的解决方案。以下就是我们讨论的解决方案：
　　首先设定一个前提，为了防止超卖现象，所有减库存操作都需要进行一次减后检查，保证减完不能等于负数。（由于MySQL事务的特性，这种方法只能降低超卖的数量，但是不可能完全避免超卖）
update number set x=x-1 where (x -1 ) >= 0;
 
解决方案1：
　　将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，并且由于Redis的写性能和读性能都远高于MySQL，这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。
　　优点：解决性能问题
　　缺点：没有解决超卖问题，同时由于异步写入DB，存在某一时刻DB和Redis中数据不一致的风险。
 
解决方案2：
　　引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。
　　优点：解决超卖问题，略微提升性能。
　　缺点：性能受限于队列处理机处理性能和DB的写入性能中最短的那个，另外多商品同时抢购的时候需要准备多条队列。
 
解决方案3：
　　将写操作前移到Memcached中，同时利用Memcached的轻量级的锁机制CAS来实现减库存操作。
　　优点：读写在内存中，操作性能快，引入轻量级锁之后可以保证同一时刻只有一个写入成功，解决减库存问题。
　　缺点：没有实测，基于CAS的特性不知道高并发下是否会出现大量更新失败？不过加锁之后肯定对并发性能会有影响。
 
解决方案4：
　　将提交操作变成两段式，先申请后确认。然后利用Redis的原子自增操作（相比较MySQL的自增来说没有空洞），同时利用Redis的事务特性来发号，保证拿到小于等于库存阀值的号的人都可以成功提交订单。然后数据异步更新到DB中。
　　优点：解决超卖问题，库存读写都在内存中，故同时解决性能问题。
　　缺点：由于异步写入DB，可能存在数据不一致。另可能存在少买，也就是如果拿到号的人不真正下订单，可能库存减为0，但是订单数并没有达到库存阀值。
 
三、总结
 
　　1、前端三板斧【扩容】【限流】【静态化】
　　2、后端两条路【内存】+【排队】


--------------------------------
31、TCP协议为什么是三次握手四次挥手，为什么不是别的
TCP 3次握手
客户端向服务器发送一个SYN（包含了SYN，SEQ）。
当服务器接收到客户端发过来的SYN时，会向客户端发送一个SYN+ACK的数据包，其实ACK的ack等于上一次发送SYN数据包的（SYN+SEQ）。
当客户端接收到服务器发送过来的SYN+ACK数据包时，当接收到后向服务器发送ACK的数据包，此时ACK数据包中的ack值等于上一次SYN中的seq+syn。
当服务器收到了客户端的发送过来的ACK数据包时，确认无误后，向客户端发送数据。
为什么要3次握手
防止已过期的连接请求报文突然又传送到服务器，因而产生错误。
Client发生一个请求连接报文可能因为网络延迟等原因，没有送达到server中。但是当这个client的请求报文送达到server时，如果没有三次握手的话，server就会直接发数据可client，这样会导致server资源的浪费。
解决“网络中存在延迟的重复分组”的问题
在不可靠信道上可靠地传输信息
因为TCP是一个可靠的协议，但是IP是一个不可靠的协议，利用TCP使IP传输过程变得可靠。这样的话，如果发生丢包，传输顺序出错等问题，TCP协议都可以解决。为了满足不可靠信息在可靠的传输信息。
那就是可以这样说，确认c/s是不是相应的服务都准备好了，只有通过了3次握手才能直接传输数据并且满足了数据可靠性的传输。

TCP 4次挥手
先由客户端向服务器端发送一个FIN，请求关闭数据传输。
当服务器接收到客户端的FIN时，向客户端发送一个ACK，其中ack的值等于FIN+SEQ
然后服务器向客户端发送一个FIN，告诉客户端应用程序关闭。
当客户端收到服务器端的FIN是，回复一个ACK给服务器端。其中ack的值等于FIN+SEQ
为什么要4次挥手？
确保数据能够完成传输。
但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。

例子：
TCP连接的三次握手：

第一次(A--->B)，SYN=1，seq=x
第二次(B--->A)，SYN=1，ACK=1，seq=y，ack=x+1 //seq为什么是y，ack为什么是x+1？
第三次(A--->B)，ACK=1，seq=x+1,ack=y+1 //seq为什么是x+1，ack为什么是y+1？

eq是序列号，这是为了连接以后传送数据用的，ack是对收到的数据包的确认，值是等待接收的数据包的序列号。
在第一次消息发送中，A随机选取一个序列号作为自己的初始序号发送给B；第二次消息B使用ack对A的数据包进行确认，因为已经收到了序列号为x的数据包，准备接收序列号为x+1的包，所以ack=x+1，同时B告诉A自己的初始序列号，就是seq=y；第三条消息A告诉B收到了B的确认消息并准备建立连接，A自己此条消息的序列号是x+1，所以seq=x+1，而ack=y+1是表示A正准备接收B序列号为y+1的数据包。
seq是数据包本身的序列号；ack是期望对方继续发送的那个数据包的序列号。
--------------------------------
32、HTTP报文有哪几个部分
请求报文：报文首部和报文主体（空行分割）
报文首部：请求行、请求首部字段、通用首部字段、实体首部字段、其他
请求行：包含用于请求的方法，请求URI和HTTP版本

响应报文：报文首部和报文主体（空行分割）
报文首部：状态行、响应首部字段、通用首部字段、实体首部字段、其他
状态行：HTTP版本，标明相应结果的状态码和原因短语。
--------------------------------
33、接口安全如何做
专线、限定IP、参数校验、md5加密
--------------------------------
34、要你实现RPC框架，你会注重什么
首先，要解决通讯的问题，主要是通过在客户端和服务器之间建立TCP连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。
第二，要解决寻址的问题，也就是说，A服务器上的应用怎么告诉底层的RPC框架，如何连接到B服务器（如主机或IP地址）以及特定的端口，方法的名称名称是什么，这样才能完成调用。比如基于Web服务协议栈的RPC，就要提供一个endpoint URI，或者是从UDDI服务上查找。如果是RMI调用的话，还需要一个RMI Registry来注册服务的地址。
第三，当A服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如TCP传递到B服务器，由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，也就是序列化（Serialize）或编组（marshal），通过寻址和传输将序列化的二进制发送给B服务器。
第四，B服务器收到请求后，需要对参数进行反序列化（序列化的逆操作），恢复为内存中的表达方式，然后找到对应的方法（寻址的一部分）进行本地调用，然后得到返回值。
第五，返回值还要发送回服务器A上的应用，也要经过序列化的方式发送，服务器A接到后，再反序列化，恢复为内存中的表达方式，交给A服务器上的应用
--------------------------------
35、linux查看cpu、内存、硬盘、网络IO、负载、端口占用情况、及某个具体进程的命令
工具    简单介绍
top    查看进程活动状态以及一些系统状况
vmstat    查看系统状态、硬件和系统信息等
iostat    查看CPU 负载，硬盘状况
sar    综合工具，查看系统状况
mpstat    查看多处理器状况
netstat    查看网络状况
iptraf    实时网络状况监测
tcpdump    抓取网络数据包，详细分析
tcptrace    数据包分析工具
netperf    网络带宽工具
dstat    综合工具，综合了 vmstat, iostat, ifstat, netstat 等多个信息
--------------------------------
36、说说一致性hash算法
Hash 算法的一个衡量指标是单调性（ Monotonicity ），定义如下：
单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。
consistent hashing 是一种 hash 算法，简单的说，在移除 / 添加一个 cache 时，它能够尽可能小的改变已存在 key 映射关系，尽可能的满足单调性的要求。
Consistent hashing 的基本思想就是将对象和 cache 都映射到同一个 hash 数值空间中，并且使用相同的hash 算法。
考量 Hash 算法的另一个指标是平衡性 (Balance):
平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。
为了解决分布是很不均衡这种情况， consistent hashing 引入了“虚拟节点”的概念

--------------------------------
37、说说类加载机制，它们是怎么设计的
类加载机制概念：
* Java虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的加载机制。*
类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括了：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（using）、和卸载（Unloading）七个阶段。其中验证、准备和解析三个部分统称为连接（Linking）
步骤：
 (1) 装载：查找和导入Class文件；
 (2) 链接：把类的二进制数据合并到JRE中；
    (a)校验：检查载入Class文件数据的正确性；
    (b)准备：给类的静态变量分配存储空间；
    (c)解析：将符号引用转成直接引用；
 (3) 初始化：对类的静态变量，静态代码块执行初始化操作
详解：
1. 装载(加载)
类的装载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 
类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。
2. 验证
验证的目的是为了确保Class文件中的字节流包含的信息符合当前虚拟机的要求，而且不会危害虚拟机自身的安全。不同的虚拟机对类验证的实现可能会有所不同，但大致都会完成以下四个阶段的验证：文件格式的验证、元数据的验证、字节码验证和符号引用验证。
1）文件格式的验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理，该验证的主要目的是保证输入的字节流能正确地解析并存储于方法区之内。经过该阶段的验证后，字节流才会进入内存的方法区中进行存储，后面的三个验证都是基于方法区的存储结构进行的。 

 2）元数据验证：对类的元数据信息进行语义校验（其实就是对类中的各数据类型进行语法校验），保证不存在不符合Java语法规范的元数据信息。 

 3）字节码验证：该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。 

 4）符号引用验证：这是最后一个阶段的验证，它发生在虚拟机将符号引用转化为直接引用的时候（解析阶段中发生该转化，后面会有讲解），主要是对类自身以外的信息（常量池中的各种符号引用）进行匹配性的校验。 
3. 准备
准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中进行分配。 
4. 解析
解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。
5. 初始化
类初始化阶段是类加载过程的最后一步，前面的类加载过程中，除了加载（Loading）阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码。 
初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式：

①声明类变量时指定初始值
②使用静态代码块为类变量指定初始值
JVM初始化步骤
1、假如这个类还没有被加载和连接，则程序先加载并连接该类
2、假如该类的直接父类还没有被初始化，则先初始化其直接父类
3、假如类中有初始化语句，则系统依次执行这些初始化语句
--------------------------------
38、你怎么做职业规划的，未来三年你有什么规划
--------------------------------
39、你目前手中有哪些offer，你会考虑我们公司吗，你对我们公司有什么想要了解的
--------------------------------
40、你为什么要离职（这个要慎重，千万不要抱怨前任公司，更不要说坏话，不然你技术再牛逼也过不了）


-------------------------------

--------------------------------
  对于WEB应用集群的技术实现而言，最大的难点就是如何能在集群中的多个节点之间保持数据的一致性，会话（Session）信息是这些数据中最重要的一块。
要实现这一点，大体上有两种方式，一种是把所有Session数据放到一台服务器上或者数据库中，集群中的所有节点通过访问这台Session服务器来获取数据；
另一种就是在集群中的所有节点间进行Session数据的同步拷贝，任何一个节点均保存了所有的Session数据。两种方式都各有优点，
第一种方式简单、易于实现，但是存在着Session服务器发生故障会导致全系统不能正常工作的风险；
第二种方式可靠性更高，任一节点的故障不会对整个系统对客户访问的响应产生影响，但是技术实现上更复杂一些。
常见的平台或中间件如microsoftasp.net和IBM WAS都会提供对两种共享方式的支持，tomcat也是这样，但是一般采用第二种方式。 

--------------------------------



